# ---------- Overriding hydra default configs ----------
hydra:
  job:
    name: contrails
  run:
    dir: ${out_dir}

# ---------- Default settings ----------
defaults:
  - dataset: contrails
  - optimizer: adam
  - scheduler: cosine

  # For hydra colorlog
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog


# ---------- Other configs ----------

#====
# Preprocessing
#====
preprocessing:
  h_resize_to: 512
  w_resize_to: 512
  mean: [0, 0, 0]  # [0.485, 0.456, 0.406]
  std: [1, 1, 1]  # [0.229, 0.224, 0.225]

#====
# Model
#====
model:
  restore_path: ${test_model}  # Restore model's weight from this path.
  base_model: resnest269e  # Pretrained model to load
  backbone_class: null
  freeze_backbone: false
  use_label_aux_min_max: false

  output_dim: ${dataset.num_classes}
  in_chans: ${dataset.in_chans}
  use_25d: false
  n_frames_before: ${dataset.n_frames_before}
  n_frames_after: ${dataset.n_frames_after}

#====
# Model head
#====
head:
  type: linear


#====
# Forwarder
#====
forwarder:
  use_label_aux_min_max: ${model.use_label_aux_min_max}
  use_meta_pos: ${model.use_meta_pos}
  use_aux_pl: ${model.use_aux_pl}
  use_amp: ${training.use_amp}
  loss:
    dice_loss_weight: 1.0
    dice_2_loss_weight: 0
    dice_inv_loss_weight: 0.1
    dice_aux_loss_weight: 1.0
    dice_2_aux_loss_weight: 0
    dice_aux_min_max_loss_weight: 0.5
    dice_aux_max_loss_weight: 0
    bce_loss_weight: 0
    bce_aux_loss_weight: 0
    dice_aux_loss_0_weight: 0

#====
# Dataset
#====
dataset:
  type: ???
  num_classes: ???


#====
# Data augmentation
# Should have effect only in training (not in validation nor test)
#====
# augmentation: null
augmentation:
  in_chans: ${dataset.in_chans}
  n_frames_before: ${dataset.n_frames_before}
  n_frames_after: ${dataset.n_frames_after}
  use_light_aug: false
  use_light_aug2: false
  use_light_aug3: false
  use_aug: false
  use_heavy_aug: false
  rotate: 15
  translate: 0.25
  shear: 3
  p_affine: 0.5
  crop_scale: 0.9
  crop_l: 0.75
  crop_r: 1.0
  p_gray: 0.1
  p_blur: 0.05
  p_noise: 0.05
  p_downscale: 0.0
  p_shuffle: 0.3
  p_posterize: 0.2
  p_bright_contrast: 0.5
  p_cutout: 0.05

#====
# Training
#====
training:
  project_name: contrails
  resume_from: null  # If set, restore all training state from that checkpoint
  debug: false  # If true, run in a debug mode
  use_wandb: false # If true, WandbLogger will be used
  seed: 0  # Random seed passed for seed_everything
  monitor: val/dice
  monitor_mode: max
  gradient_clip_val: 0.5
  accumulate_grad_batches: 1
  sync_batchnorm: true
  save_embed: false
  decode_test: false

  epoch: 10
  batch_size: 16
  batch_size_test: 16
  num_gpus: 1
  num_workers: 12
  drop_last: true  # If true, drop the last incomplete batch in training phase
  use_amp: true  # If true, use 16-bit precision for training
  use_gradient_checkpointing: false


#====
# Optimizer
#====
optimizer:
  type: ???


#====
# Scheduler
#====
scheduler:
  type: ???
  num_steps_per_epoch: null


#====
# Other essential configs
#====
out_dir: ???
test_model: null  # If set, only run test with that model
save_results: true
